{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import datasets, models, transforms\n",
    "import time\n",
    "import os\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "This is only for checking the device configuration\n",
    "IF CUDA Is present or not\n",
    "\n",
    "\"\"\"\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Hyper Parameters\n",
    "\n",
    "\"\"\"\n",
    "num_epochs = 5\n",
    "batch_size = 4\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Transformation of the Images into Tensor that too Normalised Tensor\n",
    "\n",
    "Normalize  Args:\n",
    "\n",
    "    mean (sequence): Sequence of means for each channel.\n",
    "    std (sequence): Sequence of standard deviations for each channel.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Import the Dataset\n",
    "\n",
    "\"\"\"\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.25, 0.25, 0.25))\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.25, 0.25, 0.25))\n",
    "    ]),\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cats', 'Dogs']\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'main_dir'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
    "                                          data_transforms[x])\n",
    "                  for x in ['train', 'val']}\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,\n",
    "                                             shuffle=True, num_workers=0)\n",
    "              for x in ['train', 'val']}\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Let's iterate the dataloader It is used to shuffle the dataset\"\"\"\n",
    "inputs, classes = next(iter(dataloaders['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        Every epoch will have training and validation  result\n",
    "        \n",
    "        \"\"\"\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                \n",
    "                \"\"\"\n",
    "                \n",
    "                This will set our model to training mode\n",
    "                \n",
    "                \"\"\"\n",
    "                model.train()\n",
    "            else:\n",
    "                \n",
    "                \"\"\"\n",
    "                \n",
    "                And This will set our model to evaluation mode\n",
    "                \n",
    "                \"\"\"\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            \"\"\"\n",
    "            \n",
    "            Let's iterate over the data\n",
    "            \n",
    "            \"\"\"\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                \"\"\"\n",
    "                \n",
    "                Forward \n",
    "                \n",
    "                \"\"\"\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    \"\"\"\n",
    "                    \n",
    "                    Backward with optimisation\n",
    "                    \n",
    "                    \"\"\"\n",
    "                    if phase == 'train':\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                \n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n",
      "train Loss: 0.6959 Acc: 0.6250\n",
      "val Loss: 0.8373 Acc: 0.7500\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n",
      "train Loss: 0.6534 Acc: 0.6250\n",
      "val Loss: 0.7806 Acc: 0.7500\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n",
      "train Loss: 0.5793 Acc: 0.6250\n",
      "val Loss: 0.7751 Acc: 0.7500\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n",
      "train Loss: 0.6348 Acc: 0.6250\n",
      "val Loss: 0.7276 Acc: 0.7500\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n",
      "train Loss: 0.6788 Acc: 0.5000\n",
      "val Loss: 0.7407 Acc: 0.7500\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n",
      "train Loss: 0.5890 Acc: 0.6250\n",
      "val Loss: 0.7539 Acc: 0.7500\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n",
      "train Loss: 0.4735 Acc: 1.0000\n",
      "val Loss: 0.7159 Acc: 0.7500\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n",
      "train Loss: 0.4468 Acc: 1.0000\n",
      "val Loss: 0.7232 Acc: 0.7500\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n",
      "train Loss: 0.4142 Acc: 1.0000\n",
      "val Loss: 0.7174 Acc: 0.7500\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n",
      "train Loss: 0.5419 Acc: 0.8750\n",
      "val Loss: 0.7111 Acc: 0.7500\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n",
      "train Loss: 0.3804 Acc: 1.0000\n",
      "val Loss: 0.7227 Acc: 0.7500\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n",
      "train Loss: 0.5634 Acc: 0.6250\n",
      "val Loss: 0.7238 Acc: 0.7500\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n",
      "train Loss: 0.5274 Acc: 0.7500\n",
      "val Loss: 0.7352 Acc: 0.7500\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n",
      "train Loss: 0.5411 Acc: 0.7500\n",
      "val Loss: 0.7331 Acc: 0.7500\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n",
      "train Loss: 0.6507 Acc: 0.6250\n",
      "val Loss: 0.7333 Acc: 0.5000\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n",
      "train Loss: 0.4798 Acc: 1.0000\n",
      "val Loss: 0.7479 Acc: 0.5000\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n",
      "train Loss: 0.4597 Acc: 0.8750\n",
      "val Loss: 0.7566 Acc: 0.7500\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n",
      "train Loss: 0.4839 Acc: 1.0000\n",
      "val Loss: 0.7597 Acc: 0.7500\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n",
      "train Loss: 0.3807 Acc: 1.0000\n",
      "val Loss: 0.7472 Acc: 0.7500\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n",
      "train Loss: 0.5005 Acc: 0.7500\n",
      "val Loss: 0.7705 Acc: 0.5000\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n",
      "train Loss: 0.3731 Acc: 1.0000\n",
      "val Loss: 0.7717 Acc: 0.5000\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n",
      "train Loss: 0.5275 Acc: 0.8750\n",
      "val Loss: 0.7542 Acc: 0.5000\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n",
      "train Loss: 0.5695 Acc: 0.7500\n",
      "val Loss: 0.7583 Acc: 0.5000\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n",
      "train Loss: 0.4846 Acc: 0.8750\n",
      "val Loss: 0.7493 Acc: 0.5000\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n",
      "train Loss: 0.5162 Acc: 0.7500\n",
      "val Loss: 0.7669 Acc: 0.7500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load weights of the Model\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "model = models.resnet18(pretrained= True)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Here I will modify the last fully connected layer\n",
    "\n",
    "But before that Let's get the number of feature from the Last layer\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "num_features = model.fc.in_features\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Now We will create a new layer and assign it to the Last layer \n",
    "\n",
    "nn.linear accepts args :\n",
    "\n",
    "1. Number of output features from previous layer and desire output we want from our last layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "model.fc = nn.Linear(num_features, 2)\n",
    "\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "\"\"\"\n",
    "Defining the loss function and optimiser\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "This lr.scheduler.StepLR : Decays the learning rate of each parameter group by gamma every\n",
    "step_size epochs. Notice that such decay can happen simultaneously with\n",
    "other changes to the learning rate from outside this scheduler. When\n",
    "last_epoch=-1, sets initial lr as lr.\n",
    "\n",
    "Args:\n",
    "    optimizer (Optimizer): Wrapped optimizer.\n",
    "    step_size (int): Period of learning rate decay.\n",
    "    gamma (float): Multiplicative factor of learning rate decay.\n",
    "        Default: 0.1.\n",
    "    last_epoch (int): The index of last epoch. Default: -1.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "step_learning_rate_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "model = train_model(model, criterion, optimizer, step_learning_rate_scheduler, num_epochs=25)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model_conv = torchvision.models.resnet18(pretrained=True)\n",
    "for param in model_conv.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
